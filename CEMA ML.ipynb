{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CEMA INTERNSHIP TASK - COMPUTER SCIENCE TRACK"
      ],
      "metadata": {
        "id": "6Pyzs8JYNhuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CLICK HERE FOR DETAILED GUIDANCE & DOCUMENTATION!](https://github.com/philipmudambo/cema/blob/main/README.md)"
      ],
      "metadata": {
        "id": "1RQtlI6eObar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA IMPORTATION"
      ],
      "metadata": {
        "id": "BSSeJn2NwHyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step requires access permissions before granting files access to owner's Google Drive."
      ],
      "metadata": {
        "id": "5HYS-tRak-rU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "GOOGLE DRIVE MOUNTING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YbTs03WT0qmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdZAAqH23snz",
        "outputId": "2ac1efa0-e93e-4c9e-8bc6-1f7d95094459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENVIRONMENT SET-UP"
      ],
      "metadata": {
        "id": "jijVsTktwm7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we install & import some of important libraries for this procedure.<br>\n",
        "If it/they are already installed, ignore the installation step thus import only."
      ],
      "metadata": {
        "id": "NrIBMmLolh8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gD7BQALmlhz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "EXECUTING SHELL COMMANDS\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DHzRrpoaxaxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing required libraires\n",
        "!pip install numpy\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "875EsKRKqxa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eac8e30-fb86-4213-e028-7acaadb9f5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "IMPORTING REQUIRED LIBRARIES\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8_HH4Ryex2bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #for data access & manipulationn\n",
        "import numpy as np #for tensor-flowed data structure & representation\n",
        "import tensorflow as tf #for machine learning - building, training & deployment\n",
        "from tensorflow.keras.models import Sequential #for model building\n",
        "from tensorflow.keras.metrics import Precision, Recall #for model evaluation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #for image pre-processing\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense #for building the cnn"
      ],
      "metadata": {
        "id": "tj1Gpts9V0b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA LOADING"
      ],
      "metadata": {
        "id": "6fI42kE0em3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data used in this procedure was sampled from the original dataset which can be accessed by [clicking here!](https://drive.google.com/drive/folders/1z_0JfgpLw0IgjNx68NjElKwohd_0LzbP?usp=sharing)<br> If you prefer to work with the complete 27,558 cell images data, then you can access it from TensorFlow's library by [clicking here!](https://www.tensorflow.org/datasets/catalog/malaria)"
      ],
      "metadata": {
        "id": "L2Q6gc3UcsAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "IMAGE PATH DEFINITIONS\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9Qu09KPcck6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg6EtblRVMIs"
      },
      "outputs": [],
      "source": [
        "#defining paths to data folders\n",
        "data_dir = \"/content/drive/MyDrive/CEMA ML/datasets\" #main folder containg the images\n",
        "train_dir = os.path.join(data_dir, \"training set\") #subfolder containing the training data\n",
        "test_dir = os.path.join(data_dir, \"testing set\") #subfolder containing the testing data\n",
        "#path definition of training data\n",
        "parasitized_train_dir = os.path.join(train_dir, \"parasitized\") #contains parasitized cell images\n",
        "uninfected_train_dir = os.path.join(train_dir, \"uninfected\") #contains uninfected cell images\n",
        "#path definition of testing data\n",
        "parasitized_test_dir = os.path.join(test_dir, \"parasitized\") #contains parasitized cell images\n",
        "uninfected_test_dir = os.path.join(test_dir, \"uninfected\") #contains uninfected cell images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA PRE-PROCESSING"
      ],
      "metadata": {
        "id": "SHf8NLTBe4dW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an essential step in order to transform the data we are working with into a format that is more easily & effectively processed for machine learning in order to ensure more accurate results."
      ],
      "metadata": {
        "id": "LuTPZgHRhOMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "CELL IMAGES PRE-PROCESSING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8mPR924wfJ4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating data generators for training & testing with data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, #rescaling pixel values to [0, 1]\n",
        "                                   shear_range=0.2, #randomly sheared images\n",
        "                                   zoom_range=0.2, #randomly zoomed images\n",
        "                                   horizontal_flip=True) #randomly flipped images\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) #rescaling only for testing\n",
        "#loading cell images from directories with data augmentation for training\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  #resizing images to 150 by 150 pixels\n",
        "    batch_size=32,  #training in batches of 32 images\n",
        "    class_mode='binary' #binary classification (either a cell image is parasitized or uninfected)\n",
        ")\n",
        "#loading cell images from directories for testing without augmentation\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150), # \"\n",
        "    batch_size=32, # \"\n",
        "    class_mode='binary' # \"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN5UyonbtHzn",
        "outputId": "9dae3686-5cd3-4d74-c630-6eb4399ce8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL ARCHITECHTURE"
      ],
      "metadata": {
        "id": "caPNEkaGiGpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we build the model - using CNN:"
      ],
      "metadata": {
        "id": "eiJMJCjOm8iF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "CONVOLUTIONARY NEURAL NETWORK\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gN1AWK5xjaxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() #creating a sequential model\n",
        "#1st convolutional layer\n",
        "model.add(Conv2D(32, #number of filters\n",
        "                (3, 3), #size of filters\n",
        "                 activation='relu', #activation function\n",
        "                 input_shape=(150, 150, 3)) #input data shape\n",
        ")\n",
        "model.add(MaxPooling2D((2, 2))) #adding a max pooling layer& specifying size\n",
        "#2nd convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) # \"\n",
        "model.add(MaxPooling2D((2, 2))) # \"\n",
        "#flattening output from the convolutional layers\n",
        "model.add(Flatten())\n",
        "#dense layers for classification\n",
        "model.add(Dense(64, activation='relu')) #output layer with relu activation function - with 64 units\n",
        "model.add(Dense(1, activation='sigmoid')) #otput layer with sigmoid activation - with 1 unit because its binary(0 or 1)\n",
        "#compiling the model with optimizer &  loss function\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3DT56yDQtWDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL TRAINING"
      ],
      "metadata": {
        "id": "NAiW_upN05RA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After succesffuly building the model, we have to train it:"
      ],
      "metadata": {
        "id": "HoMMo3xynL9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator), #training on all batches per epoch\n",
        "    epochs=10, #defining the number of training epochs\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator) #validation on all batches per epoch\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-ofXtert26V",
        "outputId": "c461366f-193c-4faa-817d-276a9fa5a3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 12s 1s/step - loss: 0.7029 - accuracy: 0.5050 - precision_1: 0.5172 - recall_1: 0.1500 - val_loss: 0.6729 - val_accuracy: 0.5900 - val_precision_1: 0.7812 - val_recall_1: 0.2500\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.6753 - accuracy: 0.6700 - precision_1: 0.6466 - recall_1: 0.7500 - val_loss: 0.6584 - val_accuracy: 0.7950 - val_precision_1: 0.7565 - val_recall_1: 0.8700\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.6581 - accuracy: 0.5950 - precision_1: 0.6118 - recall_1: 0.5200 - val_loss: 0.6189 - val_accuracy: 0.7000 - val_precision_1: 0.6299 - val_recall_1: 0.9700\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 13s 2s/step - loss: 0.6421 - accuracy: 0.6200 - precision_1: 0.6395 - recall_1: 0.5500 - val_loss: 0.7985 - val_accuracy: 0.5150 - val_precision_1: 0.5076 - val_recall_1: 1.0000\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.6625 - accuracy: 0.6200 - precision_1: 0.6071 - recall_1: 0.6800 - val_loss: 0.6223 - val_accuracy: 0.5550 - val_precision_1: 1.0000 - val_recall_1: 0.1100\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.5922 - accuracy: 0.7050 - precision_1: 0.6565 - recall_1: 0.8600 - val_loss: 0.5766 - val_accuracy: 0.6900 - val_precision_1: 0.6203 - val_recall_1: 0.9800\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 12s 1s/step - loss: 0.5524 - accuracy: 0.7650 - precision_1: 0.7477 - recall_1: 0.8000 - val_loss: 0.5075 - val_accuracy: 0.7350 - val_precision_1: 0.6794 - val_recall_1: 0.8900\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.5468 - accuracy: 0.7050 - precision_1: 0.6952 - recall_1: 0.7300 - val_loss: 0.5060 - val_accuracy: 0.7350 - val_precision_1: 0.6599 - val_recall_1: 0.9700\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.4763 - accuracy: 0.7650 - precision_1: 0.7477 - recall_1: 0.8000 - val_loss: 0.4306 - val_accuracy: 0.8100 - val_precision_1: 0.8780 - val_recall_1: 0.7200\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 13s 2s/step - loss: 0.5337 - accuracy: 0.6900 - precision_1: 0.6979 - recall_1: 0.6700 - val_loss: 0.4838 - val_accuracy: 0.7400 - val_precision_1: 0.9615 - val_recall_1: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bdea1f84ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">#### OBSERVATION & INTERPRETATION\n",
        "\n",
        "- **Training Accuracy**:\n",
        "  - Ranges from around 50.5% to 76.5% over the epochs.\n",
        "  - Indicates percentage of correctly classified cell image samples in the training set.\n",
        "\n",
        "- **Training Precision**:\n",
        "  - Varies between approximately 51.72% to 74.77%.\n",
        "  - Represents ratio of true positive predictions to the total positive predictions made by the model during training.\n",
        "\n",
        "- **Training Recall**:\n",
        "  - Ranges from around 15% to 86%.\n",
        "  - Measures ratio of true positive predictions to the total number of actual positives in the training set.\n",
        "\n",
        "- **Validation Accuracy**:\n",
        "  - Peaks at 81% around the 9th epoch.\n",
        "  - Indicates percentage of correctly classified samples in the validation set.\n",
        "\n",
        "- **Validation Precision**:\n",
        "  - Reaches up to 100% in the 5th epoch.\n",
        "  - Represents ratio of true positive predictions to total positive predictions made by the model during validation.\n",
        "\n",
        "- **Validation Recall**:\n",
        "  - Varies between 11% to 100%.\n",
        "  - Measures ratio of true positive predictions to total number of actual positives in the validation set.\n",
        "\n",
        "The model tends to achieve higher accuracy & precision on the training set compared to the validation set, indicating some degree of overfitting.\n",
        "Overall, the model demonstrates potential, especially with its higher precision metrics. However, further optimization may be needed to mitigate overfitting & improve generalization to unseen data."
      ],
      "metadata": {
        "id": "BWIORosJFy4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL EVALUATION"
      ],
      "metadata": {
        "id": "IG34chJ-PQoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the model, we then have to evaluate how well it performs in classification:"
      ],
      "metadata": {
        "id": "U-oOY2iWndSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#re-compiling the model with 2 additional metrics\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "#metrics evaluation\n",
        "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_generator)\n",
        "print('Test Accuracy:', test_acc)\n",
        "print('Test Precision:', test_precision)\n",
        "print('Test Recall:', test_recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjD6nQUYvh21",
        "outputId": "c7c56a50-7e6d-423e-ccc6-5628eafc7aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 3s 286ms/step - loss: 0.4838 - accuracy: 0.7400 - precision_2: 0.9615 - recall_2: 0.5000\n",
            "Test Accuracy: 0.7400000095367432\n",
            "Test Precision: 0.9615384340286255\n",
            "Test Recall: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">#### OBSERVATION & INTERPRETATION\n",
        "\n",
        "From the output, it appears the test accuracy of the model is approximately 74% while precision & recall are approximately 96.15% & 50%, respectively.\n",
        "\n",
        "- **Test Accuracy**: Implies that the model correctly classified about 74% of the test set of cell image samples.\n",
        "  \n",
        "- **Test Precision**: Implies that the model predicts a cell image sample as positive (parasitized), it's correct around 96.15% of the time.\n",
        "\n",
        "- **Test Recall**: Implies that the model correctly identified about half of the actual positive samples in the test set.\n",
        "\n",
        "These results provide insight into the model's performance on unseen data, demonstrating relatively high precision but moderate recall. Further analysis or adjustments may be required depending on the specific requirements & constraints of the application."
      ],
      "metadata": {
        "id": "wJvga5suGbXc"
      }
    }
  ]
}