# -*- coding: utf-8 -*-
"""CEMA ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FktwC1xJ-ndL5M4LWn4AhfmECa7w7Yrv

# CEMA INTERNSHIP TASK - COMPUTER SCIENCE TRACK

[CLICK HERE FOR DETAILED GUIDANCE & DOCUMENTATION!](https://github.com/philipmudambo/cema/blob/main/README.md)

# DATA IMPORTATION

```
GOOGLE DRIVE MOUNTING
```
"""

from google.colab import drive
drive.mount('/content/drive')

"""# ENVIRONMENT SET-UP

```
EXECUTING SHELL COMMANDS
```
"""

#installing required libraires
!pip install numpy
!pip install keras
!pip install tensorflow
!pip install scikit-learn
!pip install tensorflow-gpu

"""

```
IMPORTING REQUIRED LIBRARIES
```

"""

import os #for data access & manipulationn
import numpy as np #for tensor-flowed data structure & representation
import tensorflow as tf #for machine learning - building, training & deployment
from tensorflow.keras.models import Sequential #for model building
from tensorflow.keras.metrics import Precision, Recall #for model evaluation
from tensorflow.keras.preprocessing.image import ImageDataGenerator #for image pre-processing
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense #for building the cnn

"""# DATA LOADING

```
IMAGE PATH DEFINITIONS
```
"""

#defining paths to data folders
data_dir = "/content/drive/MyDrive/CEMA ML/datasets" #main folder containg the images
train_dir = os.path.join(data_dir, "training set") #subfolder containing the training data
test_dir = os.path.join(data_dir, "testing set") #subfolder containing the testing data
#path definition of training data
parasitized_train_dir = os.path.join(train_dir, "parasitized") #contains parasitized cell images
uninfected_train_dir = os.path.join(train_dir, "uninfected") #contains uninfected cell images
#path definition of testing data
parasitized_test_dir = os.path.join(test_dir, "parasitized") #contains parasitized cell images
uninfected_test_dir = os.path.join(test_dir, "uninfected") #contains uninfected cell images

"""#DATA PRE-PROCESSING

```
CELL IMAGES PRE-PROCESSING
```
"""

#creating data generators for training & testing with data augmentation
train_datagen = ImageDataGenerator(rescale=1./255, #rescaling pixel values to [0, 1]
                                   shear_range=0.2, #randomly sheared images
                                   zoom_range=0.2, #randomly zoomed images
                                   horizontal_flip=True) #randomly flipped images
test_datagen = ImageDataGenerator(rescale=1./255) #rescaling only for testing
#loading cell images from directories with data augmentation for training
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),  #resizing images to 150 by 150 pixels
    batch_size=32,  #training in batches of 32 images
    class_mode='binary' #binary classification (either a cell image is parasitized or uninfected)
)
#loading cell images from directories for testing without augmentation
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150), # "
    batch_size=32, # "
    class_mode='binary' # "
)

"""#MODEL ARCHITECHTURE

```
CONVOLUTIONARY NEURAL NETWORK
```
"""

model = Sequential() #creating a sequential model
#1st convolutional layer
model.add(Conv2D(32, #number of filters
                (3, 3), #size of filters
                 activation='relu', #activation function
                 input_shape=(150, 150, 3)) #input data shape
)
model.add(MaxPooling2D((2, 2))) #adding a max pooling layer& specifying size
#2nd convolutional layer
model.add(Conv2D(64, (3, 3), activation='relu')) # "
model.add(MaxPooling2D((2, 2))) # "
#flattening output from the convolutional layers
model.add(Flatten())
#dense layers for classification
model.add(Dense(64, activation='relu')) #output layer with relu activation function - with 64 units
model.add(Dense(1, activation='sigmoid')) #otput layer with sigmoid activation - with 1 unit because its binary(0 or 1)
#compiling the model with optimizer &  loss function
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#MODEL TRAINING"""

model.fit(
    train_generator,
    steps_per_epoch=len(train_generator), #training on all batches per epoch
    epochs=10, #defining the number of training epochs
    validation_data=test_generator,
    validation_steps=len(test_generator) #validation on all batches per epoch
)

""">#### OBSERVATION & INTERPRETATION

- **Training Accuracy**:
  - Ranges from around 50.5% to 76.5% over the epochs.
  - Indicates percentage of correctly classified cell image samples in the training set.

- **Training Precision**:
  - Varies between approximately 51.72% to 74.77%.
  - Represents ratio of true positive predictions to the total positive predictions made by the model during training.

- **Training Recall**:
  - Ranges from around 15% to 86%.
  - Measures ratio of true positive predictions to the total number of actual positives in the training set.

- **Validation Accuracy**:
  - Peaks at 81% around the 9th epoch.
  - Indicates percentage of correctly classified samples in the validation set.

- **Validation Precision**:
  - Reaches up to 100% in the 5th epoch.
  - Represents ratio of true positive predictions to total positive predictions made by the model during validation.

- **Validation Recall**:
  - Varies between 11% to 100%.
  - Measures ratio of true positive predictions to total number of actual positives in the validation set.

The model tends to achieve higher accuracy & precision on the training set compared to the validation set, indicating some degree of overfitting.
Overall, the model demonstrates potential, especially with its higher precision metrics. However, further optimization may be needed to mitigate overfitting & improve generalization to unseen data.

#MODEL EVALUATION
"""

#re-compiling the model with 2 additional metrics
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])
#metrics evaluation
test_loss, test_acc, test_precision, test_recall = model.evaluate(test_generator)
print('Test Accuracy:', test_acc)
print('Test Precision:', test_precision)
print('Test Recall:', test_recall)

""">#### OBSERVATION & INTERPRETATION

From the output, it appears the test accuracy of the model is approximately 74% while precision & recall are approximately 96.15% & 50%, respectively.

- **Test Accuracy**: Implies that the model correctly classified about 74% of the test set of cell image samples.
  
- **Test Precision**: Implies that the model predicts a cell image sample as positive (parasitized), it's correct around 96.15% of the time.

- **Test Recall**: Implies that the model correctly identified about half of the actual positive samples in the test set.

These results provide insight into the model's performance on unseen data, demonstrating relatively high precision but moderate recall. Further analysis or adjustments may be required depending on the specific requirements & constraints of the application.
"""